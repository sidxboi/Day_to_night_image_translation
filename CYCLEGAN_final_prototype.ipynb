{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Enable eager execution for debugging\n",
        "tf.config.run_functions_eagerly(False)\n",
        "#tf.data.experimental.enable_debug_mode()"
      ],
      "metadata": {
        "id": "a82HtHMQZ95Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#        CONFIGURATION\n",
        "# ===========================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 50\n",
        "LAMBDA_CYCLE = 15.0\n",
        "LAMBDA_IDENTITY = 0.5 * LAMBDA_CYCLE\n",
        "DAY_PATH = '/content/drive/MyDrive/dataset/day'\n",
        "NIGHT_PATH = '/content/drive/MyDrive/dataset/night'\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/checkpoints\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/generated_images\"\n",
        "LOG_DIR = \"/content/drive/MyDrive/logs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "YX9LC08BaCpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#        DATA AUGMENTATION\n",
        "# ===========================\n",
        "def random_jitter(image):\n",
        "    image = tf.image.resize(image, [IMG_WIDTH + 30, IMG_HEIGHT + 30])\n",
        "    image = tf.image.random_crop(image, [IMG_WIDTH, IMG_HEIGHT, 3])\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n",
        "    image = tf.image.rot90(image, k=k)\n",
        "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
        "    return image\n",
        "\n",
        "# ===========================\n",
        "#     DATASET LOADER\n",
        "# ===========================\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, [IMG_WIDTH, IMG_HEIGHT])\n",
        "    image = random_jitter(image)\n",
        "    return image\n",
        "\n",
        "def load_dataset(day_path, night_path):\n",
        "    day_images = tf.data.Dataset.list_files(day_path + '/*.jpg', shuffle=True)\n",
        "    night_images = tf.data.Dataset.list_files(night_path + '/*.jpg', shuffle=True)\n",
        "\n",
        "    day_ds = day_images.map(preprocess_image, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    night_ds = night_images.map(preprocess_image, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    return tf.data.Dataset.zip((day_ds, night_ds))\n"
      ],
      "metadata": {
        "id": "g_IYLtnnaH-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#       MODEL DEFINITIONS\n",
        "# ===========================\n",
        "def generator_model():\n",
        "    inputs = layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, 3])\n",
        "    x = layers.Conv2D(64, (7, 7), padding='same', activation='relu')(inputs)\n",
        "    x = layers.Conv2D(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    for _ in range(9):\n",
        "        skip = x\n",
        "        x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "        x = layers.Add()([x, skip])\n",
        "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    outputs = layers.Conv2D(3, (7, 7), padding='same', activation='tanh')(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "def discriminator_model():\n",
        "    inputs = layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, 3])\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(512, 4, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(1, 4, strides=1, padding='same')(x)\n",
        "    return keras.Model(inputs, x)\n",
        "\n",
        "G_day_to_night = generator_model()\n",
        "G_night_to_day = generator_model()\n",
        "D_day = discriminator_model()\n",
        "D_night = discriminator_model()\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(0.0002, 10000, 0.98)\n",
        "optimizer_G_day_to_night = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "optimizer_G_night_to_day = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "optimizer_D_day = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "optimizer_D_night = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fwGehXo2aO9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Checkpoint Setup ===\n",
        "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    G_day_to_night=G_day_to_night,\n",
        "    G_night_to_day=G_night_to_day,\n",
        "    D_day=D_day,\n",
        "    D_night=D_night,\n",
        "    optimizer_G_day_to_night=optimizer_G_day_to_night,\n",
        "    optimizer_G_night_to_day=optimizer_G_night_to_day,\n",
        "    optimizer_D_day=optimizer_D_day,\n",
        "    optimizer_D_night=optimizer_D_night\n",
        ")\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, CHECKPOINT_DIR, max_to_keep=5)\n"
      ],
      "metadata": {
        "id": "Ejr9RtI3lcEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_obj = keras.losses.MeanSquaredError()\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_day, real_night):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        fake_night = G_day_to_night(real_day, training=True)\n",
        "        fake_day = G_night_to_day(real_night, training=True)\n",
        "\n",
        "        cycled_day = G_night_to_day(fake_night, training=True)\n",
        "        cycled_night = G_day_to_night(fake_day, training=True)\n",
        "\n",
        "        same_day = G_night_to_day(real_day, training=True)\n",
        "        same_night = G_day_to_night(real_night, training=True)\n",
        "\n",
        "        disc_real_day = D_day(real_day, training=True)\n",
        "        disc_real_night = D_night(real_night, training=True)\n",
        "        disc_fake_day = D_day(fake_day, training=True)\n",
        "        disc_fake_night = D_night(fake_night, training=True)\n",
        "\n",
        "        # Generator adversarial losses\n",
        "        gen_day_to_night_loss = loss_obj(tf.ones_like(disc_fake_night), disc_fake_night)\n",
        "        gen_night_to_day_loss = loss_obj(tf.ones_like(disc_fake_day), disc_fake_day)\n",
        "\n",
        "        # Cycle consistency loss\n",
        "        total_cycle_loss = tf.reduce_mean(tf.abs(real_day - cycled_day)) + tf.reduce_mean(tf.abs(real_night - cycled_night))\n",
        "\n",
        "        # Identity loss\n",
        "        identity_loss = tf.reduce_mean(tf.abs(real_day - same_day)) + tf.reduce_mean(tf.abs(real_night - same_night))\n",
        "\n",
        "        # Total generator losses\n",
        "        total_gen_day_to_night_loss = gen_day_to_night_loss + LAMBDA_CYCLE * total_cycle_loss + LAMBDA_IDENTITY * identity_loss\n",
        "        total_gen_night_to_day_loss = gen_night_to_day_loss + LAMBDA_CYCLE * total_cycle_loss + LAMBDA_IDENTITY * identity_loss\n",
        "\n",
        "        # Discriminator losses\n",
        "        disc_day_loss = loss_obj(tf.ones_like(disc_real_day), disc_real_day) + loss_obj(tf.zeros_like(disc_fake_day), disc_fake_day)\n",
        "        disc_night_loss = loss_obj(tf.ones_like(disc_real_night), disc_real_night) + loss_obj(tf.zeros_like(disc_fake_night), disc_fake_night)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grads_G_day_to_night = tape.gradient(total_gen_day_to_night_loss, G_day_to_night.trainable_variables)\n",
        "    grads_G_night_to_day = tape.gradient(total_gen_night_to_day_loss, G_night_to_day.trainable_variables)\n",
        "    grads_D_day = tape.gradient(disc_day_loss, D_day.trainable_variables)\n",
        "    grads_D_night = tape.gradient(disc_night_loss, D_night.trainable_variables)\n",
        "\n",
        "    # Apply gradients\n",
        "    optimizer_G_day_to_night.apply_gradients(zip(grads_G_day_to_night, G_day_to_night.trainable_variables))\n",
        "    optimizer_G_night_to_day.apply_gradients(zip(grads_G_night_to_day, G_night_to_day.trainable_variables))\n",
        "    optimizer_D_day.apply_gradients(zip(grads_D_day, D_day.trainable_variables))\n",
        "    optimizer_D_night.apply_gradients(zip(grads_D_night, D_night.trainable_variables))\n",
        "\n",
        "    return total_gen_day_to_night_loss, total_gen_night_to_day_loss, disc_night_loss, disc_day_loss\n"
      ],
      "metadata": {
        "id": "bbY1bVqzaUW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Restore if checkpoint exists ===\n",
        "start_epoch = 0\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
        "    print(\"Checkpoint restored from:\", checkpoint_manager.latest_checkpoint)\n",
        "\n",
        "    # Extract last saved epoch from checkpoint filename\n",
        "    restored_ckpt = checkpoint_manager.latest_checkpoint\n",
        "    ckpt_number = restored_ckpt.split('-')[-1]\n",
        "    if ckpt_number.isdigit():\n",
        "        start_epoch = int(ckpt_number)\n",
        "    print(f\"Resuming from epoch {start_epoch+1}\")\n"
      ],
      "metadata": {
        "id": "VWdJYAe3loqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#        TRAINING LOOP\n",
        "# ===========================\n",
        "dataset = load_dataset(DAY_PATH, NIGHT_PATH)\n",
        "\n",
        "num_day = len(glob.glob(DAY_PATH + '/*.jpg'))\n",
        "num_night = len(glob.glob(NIGHT_PATH + '/*.jpg'))\n",
        "steps_per_epoch = min(num_day, num_night) // BATCH_SIZE\n",
        "\n",
        "# === Training Loop ===\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    for step, (day_img, night_img) in enumerate(dataset.repeat().take(steps_per_epoch)):\n",
        "        G_loss, F_loss, D_night_loss, D_day_loss = train_step(day_img, night_img)\n",
        "\n",
        "    # Save checkpoint after each epoch\n",
        "    checkpoint_manager.save(checkpoint_number=epoch + 1)\n",
        "    print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}: G_loss={G_loss.numpy()}, F_loss={F_loss.numpy()} | D_night_loss={D_night_loss.numpy()}, D_day_loss={D_day_loss.numpy()}\")\n",
        "\n",
        "        sample_path = sorted(glob.glob(DAY_PATH + '/*.jpg'))[0]\n",
        "        sample_img = preprocess_image(sample_path)[None, ...]\n",
        "        prediction = G_day_to_night(sample_img, training=False)[0].numpy()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "        axs[0].imshow(sample_img[0])\n",
        "        axs[0].set_title(\"Input Day\")\n",
        "        axs[1].imshow((prediction + 1) / 2)\n",
        "        axs[1].set_title(\"Predicted Night\")\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, f\"epoch_{epoch+1}.png\"))\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "M1rGLPLMQx9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#        TESTING CODE\n",
        "# ===========================\n",
        "# To test the model with a custom input image, use the following code:\n",
        "\n",
        " sample_test_img = \"your_image.jpg\"  # Replace with your test image path\n",
        " test_output_path = \"test_output.jpg\"\n",
        " generate_night_image(sample_test_img, test_output_path)\n",
        "# # # Visualization of test image\n",
        " fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        " test_input_img = Image.open(sample_test_img)\n",
        " test_output_img = Image.open(test_output_path)\n",
        "\n",
        " ax[0].imshow(test_input_img)\n",
        " ax[0].set_title(\"Test Input Image\")\n",
        " ax[0].axis(\"off\")\n",
        "\n",
        " ax[1].imshow(test_output_img)\n",
        " ax[1].set_title(\"Generated Night Image\")\n",
        " ax[1].axis(\"off\")\n",
        "\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "yt2AEnu6T_oq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}